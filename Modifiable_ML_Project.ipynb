{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPLKJQRO/UmnsDn+ubjg4/W",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/BMG2-Dev/GitWorkshop/blob/main/Modifiable_ML_Project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Malware File Detection Using AI Machine Learning"
      ],
      "metadata": {
        "id": "2VAKwN7r44VW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Imported Libraries"
      ],
      "metadata": {
        "id": "SNzXl6DP8q3F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd # Processing and analysis of data\n",
        "from google.colab import drive # Access of data from the Google drive\n",
        "import json # Reading JSON file\n",
        "from sklearn.preprocessing import OneHotEncoder, StandardScaler # Numerical scaling and categorical encoding\n",
        "from sklearn.compose import ColumnTransformer # Apply different preprocessing for different columns\n",
        "from sklearn.pipeline import Pipeline # Pipeline creating that combines modeling and preprocessing\n",
        "from sklearn.ensemble import RandomForestClassifier # Classification model\n",
        "from sklearn.metrics import classification_report # Performance evaluation of model\n",
        "import matplotlib.pyplot as plt # for visuals"
      ],
      "metadata": {
        "id": "c8FIby0S9krq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Mount Google Drive"
      ],
      "metadata": {
        "id": "lroUF1kS5j9K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Specifies that we can use data in our Google Drive under '/content/drive'.\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4IQul9MR_41G",
        "outputId": "0ba0532a-4ad5-4e84-8787-af8d6f2141eb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Reads JSON File and Formats File Into A Dataframe"
      ],
      "metadata": {
        "id": "h4LzvGXA4fsv"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_DGxZK0r7Mvd"
      },
      "outputs": [],
      "source": [
        "# used for reading a .json file and then formatting into a dataframe\n",
        "def read_and_format_attributes(file):\n",
        "  # opens and reads json file objects into data\n",
        "  with open(file, \"r\") as f:\n",
        "    data = json.load(f)\n",
        "\n",
        "  # list to store each file in the file structure\n",
        "  rows = []\n",
        "\n",
        "  # Loops through the files in the file struture\n",
        "  for feature in data:\n",
        "    row = feature['attributes']         # Starts by extracting a file metadata 'attributes'\n",
        "    row['label'] = feature['label']     # Adds label to every file in row with its feature label\n",
        "    rows.append(row)                    # Appends file row to rows list\n",
        "  df = pd.DataFrame(rows)               # Creates structured dataframe of all files in rows\n",
        "\n",
        "  return df\n",
        "\n",
        "# Load datasets\n",
        "df1 = read_and_format_attributes('/content/drive/MyDrive/AI_courses/ML/train.json')\n",
        "df2 = read_and_format_attributes('/content/drive/MyDrive/AI_courses/ML/val.json')\n",
        "df3 = read_and_format_attributes('/content/drive/MyDrive/AI_courses/ML/test.json')\n",
        "df1.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Intialize The Training, Validation, and Test DataFrames"
      ],
      "metadata": {
        "id": "W2U5m_mT8Kpm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Separate features and labels for training, validation, and testing sets\n",
        "X_train = df1.drop(columns=['label'])    # intilizes training dataset without non-attribute column 'label'\n",
        "y_train = df1['label']                   # intilizes target training labels\n",
        "\n",
        "X_vali = df2.drop(columns=['label'])     # intilizes validation dataset without non-attribute column 'label'\n",
        "y_vali = df2['label']                    # intilizes target validation labels\n",
        "\n",
        "X_test = df3.drop(columns=['label'])     # intilizes test dataset without non-attribute column 'label'\n",
        "y_test = df3['label']                    # intilizes target test labels\n",
        "\n",
        "# Define categorical, boolean, and numeric features\n",
        "categoric_features = ['extension', 'entropy']    # Categoric features for one-hot encoded\n",
        "numeric_features = ['created_minutes_ago']       # Numeric feature for scaling\n",
        "boolean_features = ['double_extension', 'executable', 'hidden', 'system', 'hash_in_malware_db'] # Boolean features\n",
        "\n",
        "# Preprocessing pipeline\n",
        "preprocessing = ColumnTransformer( transformers=[('categoric', OneHotEncoder(handle_unknown='ignore'), categoric_features),\n",
        "                                                ('numeric', StandardScaler(), numeric_features),\n",
        "                                                ('boolean', 'passthrough', boolean_features)] )"
      ],
      "metadata": {
        "id": "nuklPGjQ7Vt-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Preprocessing and Random Forest Pipeline"
      ],
      "metadata": {
        "id": "j8xG-ruw8Pkw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Creates pipeline with preprocessing and classifier combination\n",
        "pc_pipeline = Pipeline( steps=[('preprocessing', preprocessing),\n",
        "                                ('classifier', RandomForestClassifier(n_estimators=100, random_state=42))] )\n",
        "\n",
        "# Train model on training data\n",
        "pc_pipeline.fit(X_train, y_train)\n",
        "\n",
        "# Validation Set Evaluation\n",
        "vali_predi = pc_pipeline.predict(X_vali)\n",
        "vali_results = classification_report(y_vali, vali_predi, output_dict=True)\n",
        "vali_results_df = pd.DataFrame(vali_results).transpose()\n",
        "\n",
        "# Test Set Evaluation\n",
        "test_predi = pc_pipeline.predict(X_test)\n",
        "test_results = classification_report(y_test, test_predi, output_dict=True)\n",
        "test_results_df = pd.DataFrame(test_results).transpose()"
      ],
      "metadata": {
        "id": "iThtvDb17VPC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Evaluate Model Performance"
      ],
      "metadata": {
        "id": "gAuPfHVY4iMb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Validation Results:\")\n",
        "print(vali_results_df)\n",
        "\n",
        "print(\"\\nTest Results:\")\n",
        "print(test_results_df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d_jCqYFF7U86",
        "outputId": "ff4fba8d-77a8-44ba-d901-3f345ff70aff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Results:\n",
            "              precision    recall  f1-score      support\n",
            "Benign         0.762850  0.837179  0.798289   780.000000\n",
            "Ransomware     0.258824  0.253846  0.256311   260.000000\n",
            "Spyware        0.267782  0.246154  0.256513   260.000000\n",
            "Trojan         0.252381  0.203846  0.225532   260.000000\n",
            "accuracy       0.535897  0.535897  0.535897     0.535897\n",
            "macro avg      0.385459  0.385256  0.384161  1560.000000\n",
            "weighted avg   0.511256  0.535897  0.522204  1560.000000\n",
            "\n",
            "Test Results:\n",
            "              precision    recall  f1-score      support\n",
            "Benign         0.755725  0.846154  0.798387   585.000000\n",
            "Ransomware     0.268156  0.246154  0.256684   195.000000\n",
            "Spyware        0.262295  0.246154  0.253968   195.000000\n",
            "Trojan         0.274510  0.215385  0.241379   195.000000\n",
            "accuracy       0.541026  0.541026  0.541026     0.541026\n",
            "macro avg      0.390172  0.388462  0.387605  1170.000000\n",
            "weighted avg   0.512023  0.541026  0.524532  1170.000000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "For clean files, the ML AI has a little problem identifying benign files with high accuracy scores.\n",
        "\n",
        "For the malware types, the overall accuracy score is low. Low recall means malware is having a hard time being identified. The AI ML has a low precision in identifying malware in a file. A low F1 score means that there is trouble distinguishing malware.\n",
        "\n",
        "This imbalance could cause a class imbalance in identifying benign and malware files, with one type having a larger pool of data or having trouble distinguishing between specific file features.\n",
        "\n",
        "We could oversample to balance out the model training, balance by giving more importance to these malware types, or add more distinguishing features to the file so that the model can easily identify it.\n"
      ],
      "metadata": {
        "id": "rAZRaRkil5EK"
      }
    }
  ]
}